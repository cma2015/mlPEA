library(argparse)

parser <- ArgumentParser()
parser$add_argument("-trans_id", help="Input file", type="character", dest="transid")
parser$add_argument("-positive_set", help="Peak file", type="character", dest="positive_set")
parser$add_argument("-features", help="threshold", type="character", dest="features")
parser$add_argument("-output_dir", help="output directory", type="character", dest="output_dir")
parser$add_argument("-feature_num", help="feature number", type="integer", dest="feature_num")
parser$add_argument("-fasta", help="fasta file", type="character", dest="fasta")
parser$add_argument("-cpus", help="cpus", type="integer", dest="cpus")
parser$add_argument("-iterator", help="iterator", type="integer", dest="iterator")
parser$add_argument("-ifcv", help="if cross validation", type="character", dest="ifcv")
parser$add_argument("-cross", help="cross", type="integer", dest="cross")
parser$add_argument("-bagging_model", help="bagging model", type="character", dest="bagging_model")

opt <- parser$parse_args()

trans_id <- opt$transid
positive_set <- opt$positive_set
features <- opt$features
output_dir <- opt$output_dir
feature_num <- opt$feature_num
fasta_file <- opt$fasta
cpus <- opt$cpus
iterator <- opt$iterator
cross <- opt$cross
ifcv <- opt$ifcv
bagging_model <- opt$bagging_model

suppressMessages(library(tidyr))
suppressMessages(library(dplyr))
suppressMessages(library(data.table))
suppressMessages(library(snowfall))
suppressMessages(library(ROCR))

script_dir <- "/galaxy/server/tools/04_transcriptome_screening"
source("/galaxy/server/tools/04_transcriptome_screening/03_IPSoL.R")

all_sample <- scan(trans_id, what = character())
positive_sample <- scan(positive_set,what = character())
unlabeled_sample <- setdiff(all_sample, positive_sample)

corain_feature <- as.data.frame(fread(features))
rownames(corain_feature) <- corain_feature$Seqname
corain_feature <- corain_feature[,-1]

# feature selection
for (j in 1:10) {
    print(paste0("iteration number: ",j))
    negative_sample <- sample(unlabeled_sample, length(positive_sample))

    sub_feature <- subset(corain_feature, rownames(corain_feature) %in% c(negative_sample, positive_sample))
    sub_feature$authentic <- ifelse(rownames(sub_feature) %in% positive_sample, "1", "0")
    sub_feature$authentic <- as.numeric(sub_feature$authentic)

    input <- sprintf("%s/sub_feature_%s.txt",output_dir,j)
    output <- sprintf("%s/importance_%s.txt",output_dir,j)
    write.table(sub_feature, file = input, quote = F, sep = "\t")
    PU_command <- sprintf("/home/galaxy/miniconda3/envs/tf26/bin/python %s/03_MI_features_selection.py %s %s %s %s",
                        script_dir, input, output, feature_num, j)
    system(command = PU_command)
}

Importance_final <- data.frame()
for(k in 1:10){
    file_name <- paste0(output_dir,"/importance_", k, ".txt")
    df <- read.table(file_name, sep=',',header = TRUE)
    if(k == 1){
        Importance_final <- df
    }else{
        Importance_final <- merge(Importance_final, df, by = "Feature", all = TRUE)
        names(Importance_final)[-1] <- paste0("Importance", 1:k)
    }
}
Importance_final$mean_Importance <- rowMeans(Importance_final[,2:11], na.rm = TRUE)
top_n_feature <- Importance_final[order(Importance_final$mean_Importance, decreasing = TRUE),][1:feature_num,]$Feature
write.table(top_n_feature, file = sprintf("%s/top_feature.txt",output_dir), 
            quote = F, sep = "\t", row.names = F,col.names = F)
system(command = sprintf("rm %s/sub_feature*",output_dir))

feature_df <- corain_feature[,top_n_feature]
feature_df[is.na(feature_df)] <- 0
feature_df$authentic <- ifelse(rownames(feature_df) %in% positive_sample,"1","0")

result <- fPUbaggingPSOL(transfrags_id_path = trans_id , model_dir = output_dir, 
                         positive_sample = positive_sample , feature = feature_df, iterator = iterator, cpus = cpus, bagging_model = bagging_model)
negetive_increasement <- read.table(sprintf("%s/PSOL_NegativeIncreasement.txt",output_dir),header = T,sep = "\t")

result_file <- negetive_increasement %>%
  mutate(
    Diff_In_AUC_On_TestingDataSet = if_else(
      row_number() == 1,
      0,
      abs(AUC_On_TestingDataSet - lag(AUC_On_TestingDataSet))
    )
  )

Iteration_num <- which(result_file$Diff_In_AUC_On_TestingDataSet < 0.01)[2]
load(sprintf("%s/PSOL_Iteration_%s.RData",output_dir,Iteration_num))

if(ifcv == "yes"){
  # Extracting negative samples generated by PSOL
  negatives <- iterRes$finalNegatives
  featureMat <- feature_df[, -ncol(feature_df)]
  # Performing 5-fold cross-validation experiment to evaluate the performance of predictor
  cvRes <- cross_validation(featureMat = featureMat, positives = positive_sample, 
                          negatives = negatives, cross = cross,cpus = cpus)

  pdf(sprintf("%s/cross_validation_%s.pdf",
            output_dir, Iteration_num), height = 5, width = 5)
  plotROC(cvRes = cvRes)
  dev.off()
}

predictionScores <- as.data.frame(iterRes[["predictionScores"]])
colnames(predictionScores) <- "scores"

pu_remove <- unique(rownames(predictionScores)[predictionScores[,1] < iterRes[["threshold"]]])
pu_remain <- setdiff(rownames(predictionScores), pu_remove)
write.table(pu_remain,file = sprintf("%s/pu_remain_iter_%s.txt",output_dir,Iteration_num),sep = "\t",col.names = F,row.names = F,quote = F )


system(command = sprintf("/home/galaxy/miniconda3/envs/bio/bin/seqkit grep -f  %s/pu_remain_iter_%s.txt %s > %s/PUlearning.fa_tmp",
                         output_dir,Iteration_num,fasta_file,output_dir)) 
system(command = sprintf("/home/galaxy/miniconda3/envs/bio/bin/seqkit seq %s/PUlearning.fa_tmp -w 0 > %s/PUlearning.fa",output_dir,output_dir))